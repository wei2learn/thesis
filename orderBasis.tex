
\chapter{Order Basis\label{chap:OrderBasis}}

In this chapter, we give algorithms for computing a shifted order
basis of an $m\times n$ matrix of power series over a field $\mathbb{K}$
with $m\le n$. For a given order $\sigma$ and balanced shift $\vec{s}$
the first algorithm determines an order basis with a cost of $O^{\sim}(n^{\omega-1}m\sigma)$
field operations in $\mathbb{K}$, where $\omega$ is the exponent
of matrix multiplication. Here an input shift is balanced when $\max(\vec{s})-\min(\vec{s})\in O(m\sigma/n)$.
%Here $O^{\sim}$
%is just $O$ with log factors omitted and 
%$\MM\left(n,d\right)$ denotes
%the cost of multiplying two polynomial matrices with dimension $n$
%and degree $d$. 
This extends earlier work of Storjohann which only determines a subset
of an order basis that is within a specified degree bound $\delta$
using $O^{\sim}(n^{\omega}\delta)$ field operations for $\delta\ge\lceil m\sigma/n\rceil$.
While the first algorithm addresses the case when the column degrees
of a complete order basis are unbalanced given a balanced input shift,
it is not efficient in the case when an unbalanced shift results in
the row degrees also becoming unbalanced. %The column degrees of a complete basis may be unbalanced, which is
%a major issue we address in the first algorithm. When the input shift
%is unbalanced, the row degrees of the basis can also be unbalanced
%in addition to the unbalanced column degrees. For this, we present
We present a second algorithm which balances the high degree rows
and computes an order basis also using $O^{\sim}(n^{\omega}\lceil m\sigma/n\rceil)$
field operations in the case that the shift is unbalanced but satisfies
the condition $\sum_{i=1}^{n}(\max(\vec{s})-\vec{s}_{i})\le m\sigma$.%
\begin{comment}
Every problem with any unbalanced shift can be in fact reduced to
a problem with a shift that satisfying this condition if the degrees
of a resulting order basis is known. 
\end{comment}
{} %
\begin{comment}
Many unbalanced shift problems can be in fact converted to problems
satisfying this condition. 
\end{comment}
{} This condition essentially allows us to locate those high degree
rows that need to be balanced. %
\begin{comment}
In more general unbalanced shift cases, this algorithm may not work
well directly since we do not know in advance which are the high degree
rows need to be balanced. But it may work efficiently if we have an
effective way of estimating the resulting row degrees. 
\end{comment}
{} %
\begin{comment}
This extends the earlier work by the authors from ISSAC'09.
\end{comment}


In this Chapter, we assume, without any loss of generality, that $n/m$
and $\sigma$ are powers of two. This can be achieved by padding zero
rows to the input matrix and multiplying it by some power of $x$.

We first give a brief description of Storjohann's transformation for
computer a partial order basis. %
\begin{comment}
We then provide another transformation that allows us to extend the
result from a lower order Storjohann's transformation to the result
from a higher order transformation. This lead to an algorithm that
correctly computes a complete order basis. We then show that this
algorithm is efficient on problems with balanced shifts. Finally,
we present the second algorithm that works efficiently when the shift
is unbalanced but satisfies the condition 

a special case of unbalanced shift.
\end{comment}



\section{Balancing Input with Storjohann's Transformation}

\label{sub:storjohannTransformation}

For computing a $\left(\mathbf{F},\sigma,\vec{s}\right)$-basis with
input matrix $\mathbf{F}\in\mathbb{K}\left[\left[x\right]\right]^{m\times n}$,
shift $\vec{s}$ and order $\sigma$ one can view $\mathbf{F}$ as
a polynomial matrix with degree $\sigma-1$, as higher order terms
are not needed in the computation. As such the total input size of
an order basis problem is $mn\sigma$ coefficients. One can apply
the method of \citet{Giorgi2003} directly, which gives a cost of
\begin{align*}
\sum_{i=0}^{\log\sigma}2^{i}\MM(n,2^{-i}\sigma)= & \sum_{i=0}^{\log\sigma}2^{-i}\sigma\MM(n,2^{i})\\
\subset & O\left(\sum_{i=0}^{\log\sigma}2^{-i}n^{\omega}\sigma2^{i}\log2^{i}\log\log2^{i}\right)\\
= & O\left(n^{\omega}\sigma\sum_{i=0}^{\log\sigma}i\log i\right)\\
\subset & O\left(n^{\omega}\sigma\sum_{i=0}^{\log\sigma}\log\sigma\log\log\sigma\right)\\
= & O\left(n^{\omega}\sigma\log^{2}\sigma\log\log\sigma\right)=O(n^{\omega}\bar{\M}(\sigma)\log\sigma),
\end{align*}
 close to the cost of multiplying two matrices with dimension $n$
and degree $\sigma$. Note that this cost is independent of the degree
shift. This is very efficient if $m\in\Theta\left(n\right)$. However,
for small $m$, say $m=1$ as in Hermite Padé approximation, the total
input size is only $n\sigma$ coefficients. Matrix multiplication
cannot be used effectively on a such vector input.

\citet{Storjohann:2006} provides a novel way to transform an order
basis problem with small row dimension to a problem with higher row
dimension and possibly lower degree to take advantage of \citet{Giorgi2003}'s
algorithm. We provide a quick overview of a slightly modified version
of Storjohann's method. Our small modification allows a nonuniform
degree shift for the input and provides a slightly simpler degree
shift, degree, and order for the transformed problem. The proof of
its correctness is provided in \secref{transform}. In order to compute
a $\left(\mathbf{F},\sigma,\vec{s}\right)$-basis, assuming without
loss of generality that $\min\left(\vec{s}\right)=0$, we first write
\[
\mathbf{F}=\mathbf{F}_{0}+\mathbf{F}_{1}x^{\delta}+\mathbf{F}_{2}x^{2\delta}+\cdots+\mathbf{F}_{l}x^{l\delta},
\]
 with $\deg\mathbf{F}_{i}<\delta$%
\begin{comment}
I used $\deg\mathbf{F}_{i}\le\delta-1$ before, but the reviewer suggested
changing to $\deg\mathbf{F}_{i}<\delta$ and said it's slightly easier
to read. A reason to use $\le$ is to make it consistent with the
definition of minbasis. For example, $\left(\mathbf{F},\sigma,\vec{s}\right)_{\delta-1}$-basis
indicates that the degree bound is $\delta-1$. I still prefer to
use $\le$. 
\end{comment}
{} for a positive integer $\delta$, and where we assume (again without
loss of generality) that $\sigma=\left(l+1\right)\delta$. Set 
\[
{\bar{\mathbf{F}}}=\left[\begin{array}{c|cccc}
\mathbf{F}_{0}+\mathbf{F}_{1}x^{\delta} & \mathbf{0}_{m} & \mathbf{0}_{m} & \cdots & \mathbf{0}_{m}\\
\hline \mathbf{F}_{1}+\mathbf{F}_{2}x^{\delta} & \mathbf{I}_{m} & \mathbf{0}_{m}\\
\mathbf{F}_{2}+\mathbf{F}_{3}x^{\delta} & \mathbf{0}_{m} & \mathbf{I}_{m}\\
\vdots &  &  & \ddots\\
\mathbf{F}_{l-1}+\mathbf{F}_{l}x^{\delta} &  &  &  & \mathbf{I}_{m}
\end{array}\right]_{ml\times(n+m(l-1))}.
\]
 On the left side of $\bar{\mathbf{F}}$, each block $\mathbf{F}_{i}+\mathbf{F}_{i+1}x^{\delta}$
has dimension $m\times n$. On the right side, there are $l\times(l-1)$
blocks of $\mathbf{0}_{m}$'s or $\mathbf{I}_{m}$'s each having dimension
$m\times m$. The overall dimension of $\bar{\mathbf{F}}$ is $ml\times(n+m(l-1))$.
Set $\vec{s'}=\left[\vec{s},0,\dots,0\right]$ ($\vec{s}$ followed
by $m\left(l-1\right)$ $0$'s). A $({\bar{\mathbf{F}}},2\delta,\vec{s'})$-basis
can then be computed by the method of Giorgi et al. with a cost of
$O^{\sim}\left(n^{\omega}\delta\right)$ for $\delta\ge\left\lceil m\sigma/n\right\rceil $.
This transformation of Storjohann can be viewed as a partial linearization
of the original problem, where $\bar{\mathbf{F}}$ is analogous to
the coefficient matrix of $\mathbf{F}$. Note that $\bar{\mathbf{F}}$
has $l$ block rows each containing $m$ rows. We continue to use
each block row to represent $m$ rows for the remainder of the paper.

Clearly a $(\bar{\mathbf{F}},2\delta,\vec{s'})$-basis $\bar{\mathbf{P}}$
of the transformed problem is not a $\left(\mathbf{F},\sigma,\vec{s}\right)$-basis
of the original problem, as $\bar{\mathbf{P}}$ has a higher dimension
and lower degree. However, the first $n$ rows of the $(\bar{\mathbf{F}},2\delta,\vec{s'})_{\delta-1}$-basis
contained in $\bar{\mathbf{P}}$ is a $\left(\mathbf{F},\sigma,\vec{s}\right)_{\delta-1}$-basis.

Note that there is no need to set the degree parameter $\delta$ to
less than $\left\lceil m\sigma/n\right\rceil $, as this produces
fewer basis elements without a better cost. The lowest cost is achieved
when $\bar{\mathbf{F}}$ is close to square so matrix multiplication
can be used most effectively. This requires the number of block rows
$l$ of $\bar{\mathbf{F}}$ to be close to $n/m$, which requires
$\delta=\Theta\left(\left\lceil m\sigma/n\right\rceil \right)$. Recall
that $mn\sigma$ is the total size of the original $m\times n$ input
matrix $\mathbf{F}$, hence $d=mn\sigma/n^{2}=m\sigma/n$ is the average
degree of each entry of $\mathbf{F}$ if the $m$ rows of $\mathbf{F}$
are spread out over $n$ rows. Choosing $\delta=\Theta\left(\left\lceil d\right\rceil \right)$,
the cost of computing a $({\bar{\mathbf{F}}},2\delta,\vec{s'})$-basis
is then $O^{\sim}\left(n^{\omega}\left\lceil d\right\rceil \right)=O^{\sim}\left(n^{\omega}\left\lceil m\sigma/n\right\rceil \right)$.
The ceiling function here is used to take care of the case of $m\sigma\in o(n)$.
For the remainder of the paper, we assume that $m\sigma\in\Omega(n)$
in order to avoid the need for the ceiling function and so simplify
the presentation. % avoid this case for simplicity. 
Together with the assumption that $\sigma$ and $n/m$ are both powers
of two, $m\sigma/n$ is then always a positive integer in this paper.

%Let us now look at a concrete example that illustrate Storjohann's method. 

\begin{example}
\label{exm:StorjohannTransformation}Let $\mathbb{K}=\mathbb{Z}_{2}$,
$\sigma=8$, $\delta=2$ and 
\[
\mathbf{F}=[x+x^{2}+x^{3}+x^{4}+x^{5}+x^{6},~1+x+x^{5}+x^{6}+x^{7},~1+x^{2}+x^{4}+x^{5}+x^{6}+x^{7},~1+x+x^{3}+x^{7}]
\]
 a vector of size $1\times4$. Then 
\[
\bar{\mathbf{F}}=\left[{\begin{array}{cccc|cc}
x+x^{2}+x^{3} & 1+x & 1+x^{2} & 1+x+x^{2} & ~~0~ & ~0~\\
\hline 1+x+x^{2}+x^{3} & x^{3} & 1+x^{2}+x^{3} & x & ~~1~ & ~0~\\
1+x+x^{2} & x+x^{2}+x^{3} & 1+x+x^{2}+x^{3} & x^{3} & ~~0~ & ~1~
\end{array}}\right]_{3\times6}
\]
 and a $\left(\bar{\mathbf{F}},4,\vec{0}\right)$-basis is given by
\[
\bar{\mathbf{P}}=\left[{\begin{array}{cc|cccc}
~1~ & ~x~ & 1 & x^{2}+x^{3} & 0 & x+x^{2}+x^{3}\\
0 & 1 & 0 & x^{2} & x^{2}+x^{3} & 0\\
1 & 1+x & x+x^{2} & x^{2} & x^{2} & x^{2}\\
1 & 0 & 0 & 0 & 0 & 0\\
\hline 0 & 1 & 1 & 0 & x^{2} & x+x^{2}+x^{3}\\
0 & 1 & 1+x^{2} & 0 & x^{2} & x+x^{2}
\end{array}}\right].
\]
 The first two columns of $\bar{\mathbf{P}}$ have degree less than
$2$, hence its top left $4\times2$ submatrix is a $\left(\mathbf{F},8,\vec{0}\right)_{1}$-basis.
This is a low degree part of the\textbf{ $(\mathbf{F},8,\vec{0})$}-basis
\[
\mathbf{P}=\begin{bmatrix}1 & x & 1 & x^{2}\\
0 & 1 & x^{2}+x^{3} & 0\\
1 & 1+x & x & x^{3}+x^{4}\\
1 & 0 & 0 & 0
\end{bmatrix}.
\]
 Note that if $\delta$ is set to $\sigma/2=4$, then the transformed
problem is the same as the original problem. 
\end{example}

\section{\label{sub:Unbalanced-Output}Unbalanced Output }

Storjohann's transformation can be used to efficiently compute a $\left(\mathbf{F},\sigma,\vec{s}\right)_{\delta-1}$-basis
if the degree parameter $\delta$ is close to the average degree $d=m\sigma/n$.
However, if $\delta$ is large, say $\delta=\Theta\left(\sigma\right)$,
or if we want to compute a complete $\left(\mathbf{F},\sigma,\vec{s}\right)$-basis,
then the current analysis for the computation still gives the cost
estimate of  $O^{\sim}\left(n^{\omega}\sigma\right)$.

The underlying difficulty with computing a complete order basis is
that the basis can have degree up to $\sigma$. As the output of this
problem has dimension $n\times n$ and degree up to $\Theta\left(\sigma\right)$,
this may seem to suggest $O^{\sim}\left(n^{\omega}\sigma\right)$
is about the best that can be done. However, the total size of the
output, that is, the total number of coefficients of all $n^{2}$
polynomial entries can still be bounded by $O\left(mn\sigma\right)$,
the same as the size of the input. This gives some hope for a more
efficient method. 
\begin{lem}
\label{lem:boundOfSumOfShiftedDegreesOfOrderBasis}Let $\vec{t}$
be the $\vec{s}$-column degrees of a $\left(\mathbf{F},\sigma,\vec{s}\right)$-basis.
Then $\sum\vec{t}~\le~m\sigma+\sum\vec{s}$%
\begin{comment}
 and $\max_{i}\left(\vec{t}_{i}-\vec{s}_{i}\right)\le\sigma$
\end{comment}
\textup{}%
\begin{comment}
need to permute the columns to put the pivots on the diagonal.
\end{comment}
. In addition, the total size of any $\left(\mathbf{F},\sigma,\vec{s}\right)$-basis
in $\vec{s}$-Popov form is bounded by $nm\sigma$. \end{lem}
\begin{proof}
The sum of the $\vec{s}$-column degrees is $\sum\vec{s}$ at order
0, since the identity matrix is a $\left(\mathbf{F},0,\vec{s}\right)$-basis.
This sum increases by at most $r$ for each order increase, as can
be seen from the iterative computation of order bases in \citep{BeLa94,Giorgi2003}.
The second statement follows from the fact that the row degrees and
the $\vec{s}$-column degrees of any $\vec{s}$-Popov form are represented
by the pivot entries.. 
\end{proof}
\begin{comment}
As a result, the average degree of the entries of the output matrix
can be also bounded by $d=m\sigma/n$. 
\end{comment}


Let us now look at the average column degree of the output. In the
first part of our discussion on order basis computation, we assume,
without loss of generality, that $\min\left(\vec{s}\right)=0$ so
$\deg\mathbf{q}\le\deg_{\vec{s}}\mathbf{q}$ for any $\mathbf{q}\in\mathbb{K}\left[x\right]^{n}$.
The situation is simpler if the shift $\vec{s}$ is uniform since
then $\sum\vec{t}\le m\sigma$ by \lemref{boundOfSumOfShiftedDegreesOfOrderBasis}
and the average column degree is therefore bounded by $d=m\sigma/n$.
In the first part of this paper, we consider a slightly more general
case, when the shift $\vec{s}$ is \emph{balanced}, which is defined
as follows. 
\begin{defn}
\label{def:balancedShift}A shift $\vec{s}$ is balanced if $\max\vec{s}-\min\vec{s}\in O(d)=O(m\sigma/n)$. 
\end{defn}
By assuming $\min\vec{s}=0$, $\vec{s}$ is balanced if $\max\vec{s}\in O(d)$.
In this case, \lemref{boundOfSumOfShiftedDegreesOfOrderBasis} implies
$\sum\left(\vec{t}\right)\le m\sigma+\sum\left(\vec{s}\right)\in O\left(m\sigma+nd\right)=O\left(m\sigma\right)$.
Hence the average column degree of the output basis remains $O\left(d\right)$.

%From the iterative algorithms for computing order basis, computing
%a order basis to order $\sigma$ requires up to $\sigma$ iterations,
%each iteration increases the sum of column degrees of the order basis
%by at most $m$. Therefore, the sum of column degrees of an order
%$\sigma$ order basis is at most $m\sigma$.


\begin{comment}
In fact, if $\mathbf{F}\left(0\right)$ is full rank, the sum of column
degrees of an order $\sigma$ order basis is exactly $m\sigma$, as
we need exactly $\sigma$ iterations, each increases the sum of the
column degrees by exactly $m$. 
\end{comment}


The fact that a $\left(\mathbf{F},\sigma,\vec{s}\right)$-basis can
have degree up to $\sigma$ while its average column degree is $O\left(m\sigma/n\right)$
implies that an order basis can have quite unbalanced column degrees,
especially if $m$ is small. A similar problem with unbalanced output
is encountered in null space basis computation. \citet{storjohann-villard:2005}
deal with this in the following way.

Let $d$ be the average column degree of the output. Set the degree
parameter $\delta$ to twice that of $d$. This allows one to compute
at least half the columns of a basis (since the number of columns
with degree at least $\delta$ must be at most a half of the total
number of columns). One can then simplify the problem, so that the
computed basis elements are completely removed from the problem. This
reduces the dimension of the problem by at least a factor of $2$.
One then doubles the degree bound $\delta$ in order to have at least
$3/4$ of the basis elements computed. Repeating this, at iteration
$i$, at most $1/2^{i}$ of the basis elements are remaining. Therefore,
no more than $\log n$ iterations are needed to compute all basis
elements.

\input{orderBasisTransform.tex}

\input{orderBasisComputing.tex}

\input{orderBasisComplexity.tex}

\input{orderBasisRemoveCeilingFunction.tex}

\input{orderBasisUnbalanced.tex}
